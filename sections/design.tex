\section{Design} \label{sec:design}

% The aim of design: write like the larousse. High level design for someone to
% take and improve upon. 
%
% Idea is to motivate that this is well designed and well thought through.
% Key design decisions:
        
% ------------------------
% Design introduction: what is the design philosophy? why?

\af is a complex piece of systems software and therefore required a
careful design phase. In a systems security project, added code and complexity
represent more chances for vulnerabilities to appear. Therefore, it was
important to design \af to be \textbf{as minimal as possible} while fulfilling
the promise of the proposed fine-grained filtering.

To do this, we defined a \textbf{threat model} (\ref{subsec:threat-model}) and
let primary requirements (\ref{subsec:requirements}) follow. These primary
requirements are presented alongside \textit{corollary requirements}
(\ref{subsubsec:corollary-reqs}) and design assumptions
(\ref{subsec:assumptions}).

\afg architecture is visualised in Figure \ref{fig:arch-overview}. Each
section's function is motivated in turn and key design decisions are justified.
The project's nature also requires some auxiliary tooling, which is discussed
after \afg design is presented.

\subsection{Threat Model}\label{subsec:threat-model}

We started by creating a \textbf{threat model} which lays out the situations and
pre-conditions where \af is effective at protecting an application.

Firstly, we assume that 1) a \ac{ta} has gained \ac{rce} privileges on the host
machine \footnote{We refer to the machine running \af as the \textit{host
}}. That is, the \ac{ta} can execute any code they wish on the host. This is one of the most serious breaches that can happen and often
lead to denial of service, data loss, or data theft \cite{RCE_BAD}.

The attacker aims to use their \ac{rce} exploit to \textbf{escalate privilege}. This
means we assume that 2) the \ac{ta} doesn't have root privileges on the host,
but will act to get them.

\af assumes that 3) some form of \textbf{software compartmentalisation} is in
place on the host machine. This compartmentalisation confines the \ac{ta} to the
compromised compartment \cite{SOK}, preventing the \ac{ta} 
from branching to an area of the address space that has a different allowed set
of system calls. We assume that the compartmentalisation in place is at least as
broad as that shown in Figure~\ref{fig:compartments-around-vma}. That is, if an
attacker gains access to a file backed region of the address space, they will be
contained there.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.96 \linewidth]{./diagrams/compartments-around-so.drawio.pdf} 
    \caption{A diagram showing how compartment boundaries are drawn to align
    with file-backed regions of the process's \ac{vma}.}
    \label{fig:compartments-around-vma}
\end{figure}

For completeness, we also explicitly assume that the attacker does not have a
kernel-level exploit. This is out of scope as a kernel level exploit effectively
gives an attacker root access to the host.

Defining the high level requirements for \af is now possible, as we can reason
about exactly \textbf{what \af must protect against}.

% Use/reference BPF threat model
% https://www.linuxfoundation.org/hubfs/eBPF/ControlPlane%20%E2%80%94%20eBPF%20Security%20Threat%20Model.pdf#page=11.14

\subsection{Requirements} \label{subsec:requirements}

\afg key feature is that it should detect where an application makes a 
\textbf{disallowed syscall} and intervene accordingly. 

This intervention should be \textbf{user configurable}: warning the user, killing 
the malicious process, and killing all protected processes should all be
possible. This gives the user flexibility to choose how to trade-off
availability and data integrity/confidentiality on a per-application basis.

We should see a \textbf{significant reduction} in the set of syscalls a \ac{ta}
can access after compromising an application, and we want to do this
\textbf{without detrimentally impacting performance}.\todo{see if these
requirements can be made more concrete without giving numbers}

To summarise 

\begin{enumerate}
    \item \af \textit{shall} associate a distinct system call whitelist with each unique file-backed region within a process's \ac{vma}.
    \item \af \textit{shall} \textbf{identify the specific memory region} within the \ac{vma} from which a system call originates. If the invoked system call is not included in the whitelist associated with that originating region, \af \textit{shall} \textbf{trigger an intervention}.
    \item The intervention action taken by \af upon detecting a non-whitelisted system call \textit{shall} be \textbf{configurable by the user}. The available configuration options \textit{shall} include, at minimum: (a) logging a warning, (b) terminating the process that issued the disallowed syscall, and (c) terminating all processes currently being monitored by \af.
    \item \af \textit{shall} demonstrably achieve a \textbf{greater reduction in process privileges} compared to a standard Linux seccomp filter configuration. This security enhancement \textit{shall} be achieved while incurring a runtime performance overhead deemed acceptable within pre-defined limits.
\end{enumerate}

\subsection{Corollary Requirements} \label{subsubsec:corollary-reqs}

The primary requirements listed above leave some questions unanswered.
Developers don't know which system calls their application makes\todo{does this
need a citation?} - let alone
which shared libraries are responsible for each syscall. Therefore, we also
provide \textbf{automated whitelist generation tooling} with \af. 

Syscall filtering literature hasn't defined a standard way to measure the
reduction in privilege that a particular filtering strategy provides. Therefore,
we look to propose our own metric to quantify the level of privilege reduction
afforded by \af when compared to seccomp.

\subsection{Assumptions}\label{subsec:assumptions}

There are some rare cases which require significant engineering effort to cover.
In these cases, we make some \textbf{simplifying assumptions}. This was done
primarily to avoid adding unnecessary code and complexity to \afg design. 
 
One of these is handling the case where \acg{libc} address space changes during
execution. This is technically possible, but is rarely seen in production.
Care needs to be taken to ensure that this assumption doesn't introduce a
security risk during the implementation. System calls made in the case where 
\ac{libc} has been changed should be treated as disallowed syscalls.

% XXX: this requirement is satisfied by IMPLEMENTATION DETAILS
%  - libc moved => libc calls will be treated as non-libc
%  - => check to see if in libc whitelist; no libc whitelist guaranteed
%  - (because of generation) => disallowed

We also assume that \ac{libc} is mapped contiguously in memory, shown in
Figure~\ref{fig:libc-contiguous}. Again, this is
true (almost) without exception\footnote{Custom patches to the kernel could
violate this invariant} and reduces the code base size and complexity.
It is also important to note that this assumption does not introduce a security
risk due to the way that syscall site identification is implemented and shown in
Section \ref{subsubsec:impl-find-site-opt} \cite{glibc-dl-map-segments-h}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6 \linewidth]{./diagrams/libc-contig-vs-noncontig.drawio.pdf} 
    \caption{A figure showing what a contiguous mapping of \ac{libc} in a
    process's address space vs a non-contiguously mapped \ac{libc}.}
    \label{fig:libc-contiguous}
\end{figure}

\subsection{Limitations}

The limitations of this design are linked to these assumptions. If \acg{libc}
address is not contiguous, then \af will not be able to find non-\ac{libc}
addresses correctly. This will result in syscalls being marked as having 
\ac{libc} as a callsite, which will result in the syscall filter being
tripped as discussed in Section \ref{subsubsec:err-handling}. 

The other obvious limitation of this design is that it only makes sense for
dynamically linked executables. Statically linked executables do not make use of
shared libraries and therefore making filters for each shared library does not
make sense.

With the relevant background fully explained and the requirements defined, we
can move on to presenting the design of \afss.~ 

\subsection{Architecture} \label{subsec:arch}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8 \linewidth]{./diagrams/high-level-overview.drawio.pdf} 
    \caption{High level overview of \afg architecture}
    \label{fig:arch-overview}
\end{figure}

\af is comprised of a (kernel-space) backend and a userspace frontend.
\ac{bpf} maps and ringbuffers are used to allow the backend and frontend to
communicate. The frontend is responsible for spawning the filtered application,
handling configuration, and \textit{attaching} the \ac{bpf} program to it's
tracepoint (discussed further in Section \ref{sec:implementation}).

The backend of \af is made up of a single \ac{bpf} program and \ac{bpf}
maps/ringbuffers to communicate with userspace.
The program is attached to a \textbf{raw tracepoint}, and runs every time
a system call is made - even ones not called by by the app being filtered.

\subsubsection{Determining Which Syscalls to
Filter}\label{subsec:design-fork-following}

This means \af needs a way to identify which system calls were made by the
protected app. \acp{pid} of filtered processes
need to be stored in \iac{bpf} map. Then, on every system call, we check if the
called process's \ac{pid} is in the map of filtered processes. If not, ignore
the system call. Otherwise, we continue with the filtering.

We also want to apply the filter to any child processes the
application might create - this is called \textbf{fork following}. The reason for this is two-fold: a common workflow for
web servers (such as nginx) \cite{apache-prefork-2.4, nginx-inside-performance-scale-2015} is to fork on receiving a request; the second is
that if a \ac{ta} could just call fork() to remove the syscall filter, our
solution would not be secure. Fork following is visualised in
Figure~\ref{fig:fork-follow-process-tree} with two process trees. With fork
following, each child process is protected by addrfilter. Without it, children
are left unprotected.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8 \linewidth]{./diagrams/fork-following.drawio.pdf} 
    \caption{A diagram showing two different process trees: one with fork
    following (left) and one without fork following (right).}
    \label{fig:fork-follow-process-tree}
\end{figure}


To do this, we can also check if the parent process's \ac{pid} is in the follow
map. If it is, we add the calling \ac{pid} to the follow map, and continue with
the filtering. So, we only ignore syscall if \textbf{neither the current nor
parent \ac{pid} exists in the follow map}.

Having decided to filter a syscall, we need to identify where in the process's
address space the syscall was made. We might use the value of the \ac{pc} when
the syscall was made, but this turns out to be unhelpful.
Almost all system calls are made via \ac{libc} in a dynamically linked 
application, and so the \ac{pc} almost always points to \ac{libc} instead of the
library that actually made the syscall.

\subsubsection{Finding the Syscall Site}\label{subsubsec:find_syscall}

Therefore, \af must find the \textbf{first non-\ac{libc} return pointer in the
userspace stack}, and treat this address as the true syscall site. In other
words, we trace through the sequence of function calls that led to the system
calls and find the first call that wasn't made by libc.

For example consider a ``hello, world'' program in C (see Listing~\ref{lst:hello-world}). \texttt{printf()} is a 
function implemented in \ac{libc} which invokes the \texttt{write()} syscall
behind the scenes, which in turn will call the \texttt{syscall} x86
instruction\footnote{This is a simplified stack trace: in \texttt{musl},
\texttt{write()} calls a wrapper function \texttt{syscall\_cp\_c()}. However,
the idea still holds.}. This means the userspace stack may look something the stack
presented in Figure~\ref{fig:hello-world-stack}


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.4 \linewidth]{./diagrams/hello-world-stack.drawio.pdf} 
    \caption{An example representation of what a \textit{hello, world}
    application's user stack may look like.}
    \label{fig:hello-world-stack}
\end{figure}

The addresses shown in the diagram are \textbf{return pointers}: these are the
memory address of the instructions which added a new frame to the stack. In this
context, it's helpful to think of return pointers as the \textbf{address of a
function}. Note also that the top few stack frames all belong to \ac{libc}, with
the main binary a few frames deeper.

The idea is that here we want to classify this syscall as having been made from
the \texttt{main} binary, not from \ac{libc}. We can do this by
\textit{unwinding the stack} until we find a return pointer which isn't within
\acg{libc} address space. This return pointer is then used as the syscall
invocation site, as shown in Figure~\ref{fig:stack-unwinding}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8 \linewidth]{./diagrams/stack-unwinding.drawio.pdf} 
    \caption{A figure showing \textit{why} stack unwinding is needed to find the
    correct syscall invocation site.}
    \label{fig:stack-unwinding}
\end{figure}

\subsubsection{Finding the Calling Shared Object File}\label{subsubsec:find_so}

Having found the memory address of the function which made the system call, we
can now figure out which shared library made the system call. Doing this is a
question of checking the process's \ac{vma} to find which memory region the
function belongs to. 

Each shared library exists in the \ac{vma} as a \texttt{file backed memory region}.
In-kernel, the \ac{vma} is implemented as a \texttt{vma\_struct} struct with a
(indirect) reference to the name of it's backing file. Thus, finding which
shared library ``owns'' the syscall site is a question of finding the
corresponding \texttt{vma\_struct} struct and reading the filename.
Alternatively, this information can be read from userspace via the
\texttt{/proc/PID/maps} pseudofile.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8 \linewidth]{./diagrams/core-filter-flowchart.drawio.pdf}
    \caption{A figure showing \afg core filtering logic at a high level.}
    \label{fig:core-filter-flowchart}
\end{figure}

\subsubsection{To Kill or not to Kill?}

Knowing which shared object file made the syscall allows us to find the correct
syscall whitelist and intervene if need be.

To do this, we keep a mapping from shared library filename to a set of allowed
system calls. We use the previously calculated filename as a key to this map to
retrieve some (pre-configured) whitelists. If the syscall number is in the
whitelist, no action is taken and the \ac{bpf} tracepoint returns with code 0.

If the syscall isn't on the whitelist, \af will intervene. The intervention
policy is user-configurable and has to be read from a config map. Userspace is
informed that a syscall has tripped the filter as the offending \ac{pid} is
written to a ringbuffer. If the policy is set to kill the process (or all 
processes in the \ac{pid} filtering map), \af sends a kill signal to the 
offending \ac{pid}. 

When userspace reads \iac{pid} from the ringbuffer, it acts according to how it was
configured. A warning will be logged in warn mode, but in ``kill all'' mode, a
kill signal will be sent to each \ac{pid} in the filtering map. This has to be
done asynchronously (by userspace) as \ac{bpf} only allows you to send signals
to the calling process. The filtering process is summarised in pseudocode in
Listing~\ref{lst:syscall-filter} and visualised in 
Figure~\ref{fig:core-filter-flowchart}.

This design is minimal, modular, and easy to reason about. It can be achieved
with a single \ac{bpf} program running on the \texttt{raw\_tp/sys\_enter}
tracepoint with two core maps: one for storing the \acp{pid} of filtered apps
and the other for mapping shared library names to syscall whitelists.

What's been laid out here is the interesting part of the application
- the core filtering logic. The frontend is much larger (in terms of LoC) than
the \ac{bpf} program, and also serves important functions in making the system
work.

\subsubsection{Configuring Whitelists and \ac{libc}}

The frontend is responsible for parsing the \af whitelists and loading them into
the whitelist map. We looked to build on existing standards for defining
syscall whitelists but found none suitable for our use case. Seccomp filters,
for example, are defined as a \iac{bpf} program - this isn't user friendly and
doesn't allow for mapping shared libraries to syscall filters. Therefore, we defined our
own standard: a very simple TOML file. An example is provided in
Listing~\ref{lst:toml-whitelist}.

The frontend is also responsible for supporting performance optimisations
discussed in Section \ref{sec:implementation}. One of these optimisations is
to keep track of \acp{libc} address space in a map, as we assume \acp{libc} won't
change. The frontend is responsible for finding the filtered app's \ac{libc}
address range and storing it in a map.

Ensuring that frontend functionality such as parsing whitelists is correct is
trivial with unit tests. Testing \ac{bpf} however is much more difficult.
Writing tests is technically possible but requires mocking a lot of key system
resources: crucially for us, the stack and the \ac{vma}. Having to mock core
functionality of a system often leads to brittle tests which aren't effective -
therefore, we chose a different method of validation and evaluation.

\subsection{Validation and Evaluation}

\todo{make this more brief and move some detail to evaluation}

Validation of \af happens in two phases: first, we make sure that the \ac{bpf}
program we've written is not interfering with normal syscall functionality. Then,
we test that our filtering system works - that is, \af intervenes if and only if
a syscall that is not on the whitelist is made.

To make sure that \af does not interfere with normal syscall functioning, we
propose to use the \acg{ltp} syscall test suite. We will run the suite on our
test bench with and without \af enabled and make sure that the results are the
same.

Due to the problems with mocking and automating testing (expanded on in Section
\ref{sec:evaluation}), we will favour a manual approach to ensuring that the 
syscall filtering works as expected. Writing a comprehensive test harness in requires 
significant engineering effort: likely more than developing the solution. 

Therefore, we will opt for validation via manual
verification. During development, we will write a set of programs with a stack 
that is easy to inspect with tools like \texttt{gdb}. We will use a small set of
syscalls and dynamically generate whitelists (as discussed in
\ref{subsubsec:additional-tooling}). Using a restricted set of syscalls allows
us to manually add and remove them from the whitelists and observe program
behaviour.

Evaluation will also involve two phases. First, we will investigate the degree
of privilege reduction that a developer can expect from using \af on an
application. To do this, we define a \textit{privilege metric} and compare how
privileged seccomp-filtered applications are vs \afss-filtered applications.
\todo{forward-ref privilege metric}

We then look to evaluate how costly \af is at runtime. To do this, we will take
a broad array of benchmarks informed by modern syscall filtering literature and
run them with \af enabled. We will also run the same set of syscalls with a
seccomp filter and with no filter, enabling comparison with a state of the art
filtering system and with a baseline.

We also intend to find use cases where \af is not suitable due to performance
overhead. Therefore, we will use our preliminary findings to stress \af and
speculate about application characteristics which most impact performance.

To do this evaluation, we need additional tooling. As discussed, we need two
way to generate per-library syscall whitelists. We also need some way to turn
these whitelists into a simple seccomp filter, as well as a tool to compute the
privilege reduction seen by using \af over seccomp. The design of these tools are
briefly discussed in Section \ref{subsubsec:additional-tooling}.

\subsection{Additional Tooling}\label{subsubsec:additional-tooling}

The first additional tool that we implemented and \textbf{built in to \af} was
the whitelist generator. This whitelist generator works via dynamic analysis,
which is not a gold standard for whitelist generation. For this use case,
however, we think this acceptable - whitelist generation is orthogonal to our
work and is its own field of research. We have implemented a generator here
primarily to aid development and evaluation, but more work is needed to create a
production-ready generator based on static analysis.

We implement the whitelist generator using a lot of the same functionalities of
\af. The key difference is that after identifying the syscall site, we write a
syscall number to the syscall site's map (recall that at this stage \af would
check to see if the syscall number was in the site's map and intervene if need
be). When the program finishes executing (or on Ctrl-C), the frontend reads the
contents of the bpf whitelist map and marshals the results to a TOML file.
The pseudocode is provided in Listing~\ref{lst:generator-pseudocode} and shows
that the generation code makes heavy use of \afg functionality.

We also need a tool that can launch an application with a seccomp filter enabled.
The tool takes as arguments an \af syscall whitelist
and a path to an executable, parses the whitelist and generates a single
seccomp filter. This filter is made by taking the union of each shared 
library's allowed set of syscalls present in the \af whitelist. The filter can
then be applied to a benchmark to provide comparison data. This tool will be
referred to as \texttt{af-seccomp}.

The final additional tool we need is an evaluation tool, \texttt{syso}.
\texttt{syso} takes in a binary as input and prints a comparison of the 
binary's privilege levels \todo{forward reference metric} when \af and
seccomp are applied. It also saves some raw data to disc for further post
processing: a JSON mapping from syscall numbers to number of times executed,
broken down by library. An example of this is available in
Listing~\ref{lst:syso-data-dump}.

This section looked to motivate the minimalist design philosophy, threat model,
and requirements for \af. We designed how \af should behave on each system call,
and discussed the need for kernel-space and user-space code. We also looked
forward to evaluating our solution and designed required additional tooling.

With these evaluation tools defined, the next step is to turn our design into a
working solution. In Section \ref{sec:implementation}, we show how the raw 
tracepoint attachment, BPF map structures, stack-unwinding logic and userspace 
frontend were implemented to realise the filtering, whitelist generation and 
seccomp-wrapper utilities described above.
